{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad490bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from daart.data import DataGenerator, compute_sequence_pad\n",
    "from daart.eval import get_precision_recall, run_lengths\n",
    "from daart.io import get_expt_dir\n",
    "from daart.transforms import ZScore\n",
    "\n",
    "from daart_utils.data import DataHandler\n",
    "from daart_utils.models import compute_model_predictions, get_default_hparams\n",
    "#from daart_utils.paths import data_path, results_path\n",
    "from daart_utils.plotting import plot_heatmaps\n",
    "import ssm\n",
    "from ssm.util import random_rotation, find_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ecba29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model defined in /Users/blau/Projects/daart/results_gmdgm/ssm_v1/dtcn/rgt_v1/version_0/hparams.yaml\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/blau/Projects/daart/results_gmdgm/ssm_v1/dtcn/rgt_v1/version_0/hparams.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2105e6cc75df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#arch_file = os.path.join(version_bdir, 'hparams.yaml')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading model defined in %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0march_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mhparams_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mhparams_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/blau/Projects/daart/results_gmdgm/ssm_v1/dtcn/rgt_v1/version_0/hparams.yaml'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from daart.io import get_expt_dir, find_experiment\n",
    "from daart.models import Segmenter, RSLDS\n",
    "\n",
    "#from daart_utils.session_ids.fly import SESS_IDS_TRAIN_5, SESS_IDS_TEST\n",
    "#from daart_utils.session_ids.fly import label_names\n",
    "\n",
    "#ssm labels\n",
    "label_names = ['right', 'left', 'top', 'bottom']\n",
    "\n",
    "# save predicted states from models\n",
    "save_states = True\n",
    "# overwrite predicted states from models\n",
    "overwrite_states = False\n",
    "# compute state statistics like median bout duration and behavior ratios\n",
    "compute_state_stats = False\n",
    "\n",
    "dataset = 'ssm'\n",
    "input_type = 'markers'\n",
    "# input_type = 'features-simba'\n",
    "sequence_length = 500\n",
    "batch_size = 8\n",
    "ignore_background = True\n",
    "anneal_start = 25\n",
    "anneal_end = 75\n",
    "\n",
    "\n",
    "sess_ids_test = ['ssm_v1']\n",
    "# load model\n",
    "\n",
    "#expt_dir = get_expt_dir(os.path.join(results_path, dataset), sess_ids)\n",
    "#print(expt_dir)\n",
    "\n",
    "# fill out hparams\n",
    "model_type = 'dtcn'\n",
    "tt_expt_dir = 'test'\n",
    "lambda_weak = 0\n",
    "lambda_strong = 1\n",
    "lambda_pred = 0\n",
    "\n",
    "ss_algo = 'weak'  # 'weak' | 'pseudo_labels' | 'task'\n",
    "\n",
    "# fill out hparams\n",
    "backbone = 'dtcn'\n",
    "model_class = 'rslds'\n",
    "# tt_expt_dir = 'ssl_test2'  # fly, ibl\n",
    "hparams = get_default_hparams(\n",
    "    model_class=model_class, device='cuda', sequence_length=sequence_length, n_lags=4,\n",
    "    input_type=input_type, backbone=backbone, batch_size=batch_size,\n",
    "    anneal_start=25, anneal_end=75, prob_threshold=0.9,  # pseudo_labels params\n",
    ")\n",
    "hparams['sequence_pad'] = compute_sequence_pad(hparams)\n",
    "\n",
    "#hparams['device'] = 'cuda'\n",
    "hparams['device'] = 'cpu'\n",
    "\n",
    "version_dir = \"/Users/blau/Projects/daart/results_gmdgm/ssm_v1/dtcn/rgt_v1/version_0\" #os.path.join(hparams['tt_expt_dir'], version_str)\n",
    "hdir = \"/Users/blau/Projects/daart/results_gmdgm/ssm_v1/dtcn/rgt_v1/version_0\"\n",
    "model_file = os.path.join(version_dir, 'best_val_model.pt')\n",
    "arch_file = os.path.join(hdir, 'hparams.yaml')\n",
    "#arch_file = os.path.join(version_bdir, 'hparams.yaml')\n",
    "print('Loading model defined in %s' % arch_file)\n",
    "with open(arch_file, 'rb') as f:\n",
    "    hparams_new = yaml.safe_load(f)\n",
    "hparams_new['device'] = hparams.get('device', 'cpu')\n",
    "model_0 = RSLDS(hparams_new)\n",
    "model_0.load_state_dict(torch.load(\n",
    "    model_file, map_location=lambda storage, loc: storage))\n",
    "model_0.to(hparams_new['device'])\n",
    "model_0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9798955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true_states, inf_states, num_states):\n",
    "    confusion = np.zeros((num_states, num_states))\n",
    "    ztotal = np.zeros((num_states, 1))\n",
    "    for i in range(num_states):\n",
    "        for ztrue, zinf in zip(true_states, inf_states):\n",
    "            for j in range(num_states):\n",
    "                confusion[i, j] += np.sum((ztrue == i) & (zinf == j))\n",
    "            ztotal[i] += np.sum(ztrue==i)\n",
    "    return confusion / ztotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_hand = {}\n",
    "state_overlaps_0 = {}\n",
    "# state_overlaps_1 = {}\n",
    "state_probs_0 = {}\n",
    "# state_probs_1 = {}\n",
    "states_0 = {}\n",
    "# states_1 = {}\n",
    "state_overlaps = {}\n",
    "print((hparams['trial_splits']))\n",
    "\n",
    "inferred_latents = []\n",
    "for expt_id in sess_ids_test:\n",
    "        \n",
    "    print(expt_id)\n",
    "    \n",
    "    # initialize data handler; point to correct base path\n",
    "    handler = DataHandler(expt_id, base_path=os.path.join(data_path, dataset))\n",
    "    if input_type == 'markers':\n",
    "        markers_file = handler.get_marker_filepath()\n",
    "    else:\n",
    "        markers_file = handler.get_feature_filepath(dirname=input_type)\n",
    "\n",
    "    hand_labels_file = os.path.join(\n",
    "                \"/Users/blau/Projects/daart/data/\", 'labels-hand', expt_id + '_labels.csv')\n",
    "\n",
    "    # define data generator signals\n",
    "    signals = ['markers', 'labels_strong']\n",
    "    transforms = [ZScore(), None]\n",
    "    paths = [markers_file, hand_labels_file]\n",
    "\n",
    "    # build data generator\n",
    "    data_gen_test = DataGenerator(\n",
    "        [expt_id], [signals], [transforms], [paths], device=hparams['device'], \n",
    "        batch_size=hparams['batch_size'], trial_splits='1;1;0;0', \n",
    "        sequence_pad=hparams['sequence_pad'], sequence_length=hparams['sequence_length'],\n",
    "        input_type=hparams['input_type'])\n",
    "    print('----------------------------')\n",
    "    print(data_gen_test)\n",
    "    print('----------------------------')\n",
    "    print('\\n')\n",
    "\n",
    "    # load hand labels\n",
    "    handler.load_hand_labels()\n",
    "    states = np.argmax(handler.hand_labels.vals, axis=1)\n",
    "    cutoff = int(np.floor(states.shape[0] / hparams['batch_size'])) * hparams['batch_size']\n",
    "    #states = states[:cutoff]\n",
    "    states_hand[expt_id] = states\n",
    "    \n",
    "    # compute predictions\n",
    "    print('computing predictions for model 0...', end='')\n",
    "    tmp = model_0.predict_labels(data_gen_test, return_scores=True)\n",
    "    labels_pred = np.vstack(tmp['qy_x_probs'][0])\n",
    "    \n",
    "    inferred_latents = np.vstack(tmp['qz_xy_mean'][0])\n",
    "    yhat = np.vstack(tmp['qy_x_probs'][0])\n",
    "    \n",
    "    weights = tmp['pz_mean']\n",
    "    labels_model_ = np.argmax(labels_pred, axis=1)\n",
    "    probs_max = np.max(labels_pred, axis=1)\n",
    "    labels_model = np.copy(labels_model_)\n",
    "    # labels_model[probs_max < 0.75] = 0\n",
    "    state_probs_0[expt_id] = labels_pred\n",
    "    states_0[expt_id] = labels_model\n",
    "    \n",
    "    states = states[:len(labels_model)]\n",
    "    states_hand[expt_id] = states\n",
    "    print('done')\n",
    "    \n",
    "\n",
    "    print('states shape: ', states.shape)\n",
    "    print('pred shape: ', states_0[expt_id].shape)\n",
    "    state_overlaps_0[expt_id] = confusion_matrix(\n",
    "        [states[states > 0]], [states_0[expt_id][states > 0]], num_states=len(label_names))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_all_hand = []\n",
    "states_all_0 = []\n",
    "# states_all_1 = []\n",
    "\n",
    "# for expt_id in sess_ids_test:\n",
    "#     s = states_hand[expt_id]\n",
    "#     states_all_hand.append(states_hand[expt_id])\n",
    "#     states_all_0.append(states_0[expt_id])\n",
    "# #     states_all_1.append(states_1[expt_id][s > 0])\n",
    "\n",
    "# state_overlaps_all_0 = confusion_matrix(\n",
    "#     states_all_hand, states_all_0, num_states=len(label_names))\n",
    "\n",
    "\n",
    "for expt_id in sess_ids_test:\n",
    "    s = states_hand[expt_id]\n",
    "    states_all_hand.append(states_hand[expt_id])#[s > 0])\n",
    "    states_all_0.append(states_0[expt_id])#[s > 0])\n",
    "#     states_all_1.append(states_1[expt_id][s > 0])\n",
    "\n",
    "state_overlaps_all_0 = confusion_matrix(\n",
    "    states_all_hand, states_all_0, num_states=len(label_names))\n",
    "\n",
    "# state_overlaps_all_1 = confusion_matrix(\n",
    "#     states_all_hand, states_all_1, num_states=len(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b61333",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "im = plt.imshow(state_overlaps_all_0[:, :], vmin=0, vmax=1, cmap='Reds')#'Greys_r')\n",
    "plt.title('Model SSM Data')\n",
    "plt.yticks(np.arange(len(label_names)), label_names[:])\n",
    "plt.xticks(np.arange(len(label_names)), label_names[:], rotation=45, ha='right')\n",
    "plt.colorbar()\n",
    "# plt.savefig('/home/mattw/Dropbox/research-text/papers/2021-daart/figs/state_compare_w_wo_ab/model_0.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, z, x = model_0.sampler(10000)\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "npr.seed(12345)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "color_names = [\"windows blue\", \"red\", \"amber\", \"faded green\"]\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "def plot_trajectory(z, x, ax=None, ls=\"-\"):\n",
    "    zcps = np.concatenate(([0], np.where(np.diff(z))[0] + 1, [z.size]))\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = fig.gca()\n",
    "    for start, stop in zip(zcps[:-1], zcps[1:]):\n",
    "        \n",
    "        ax.plot(x[start:stop + 1, 0],\n",
    "                x[start:stop + 1, 1],\n",
    "                lw=1, ls=ls,\n",
    "                color=colors[z[start] % len(colors)],\n",
    "                alpha=1.0)\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "new_y = []\n",
    "for ny in y:\n",
    "    m = torch.argmax(ny).item()\n",
    "    new_y.append(m)\n",
    "#print(new_y)\n",
    "new_y = np.array(new_y)\n",
    "\n",
    "z_new = []\n",
    "for zn in z:\n",
    "    m = zn.detach().numpy()\n",
    "    z_new.append(m)\n",
    "z_new = np.array(z_new)\n",
    "\n",
    "new_x = []\n",
    "for xn in x:\n",
    "    m = xn.detach().numpy()\n",
    "    new_x.append(m)\n",
    "new_x = np.array(new_x)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2, 3]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "plot_trajectory(new_y, z_new, ax=ax0)\n",
    "plt.title(\"True Trajectory\")\n",
    "\n",
    "\n",
    "print('yn', new_y.shape, new_y[:15])\n",
    "print('zn', z_new.shape, z_new[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_path_latents = '/Users/blau/Projects/daart/daart_utils/data/ssm/latents.npy'\n",
    "true_latents = np.load(markers_path_latents)\n",
    "\n",
    "\n",
    "path_labels = '/Users/blau/Projects/daart/daart_utils/data/ssm/labels.npy'\n",
    "true_labels= np.load(path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f54d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform transforms\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "z = true_latents\n",
    "zhat = inferred_latents\n",
    "\n",
    "# find the linear mapping from z to zhat; important to not fit the intercept!\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(zhat, z)\n",
    "R = lr.coef_  # might need to reshape this into a matrix\n",
    "print(R.shape, R)\n",
    "# # compute the updated dynamics matrix for each state; assume the learned matrices are stored in a list called As for simplicity\n",
    "# As_rotated = [None for _ in range(num_states)]\n",
    "# for k in range(num_states):\n",
    "#     As_rotated[k] = R @ As[k] @ np.linalg.inv(R)\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(yhat, true_labels)\n",
    "YM = lr.coef_  # might need to reshape this into a matrix\n",
    "print(YM.shape, YM)\n",
    "    \n",
    "# z_t = R A R^{-1} z_{t-1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67394780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_new.shape)\n",
    "z_R = np.zeros_like(z_new)\n",
    "for i, zn in enumerate(z_new):\n",
    "    zr = np.matmul(R, zn)\n",
    "    z_R[i] = zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 6)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2, 3]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "plot_trajectory(new_y, z_R, ax=ax0)\n",
    "plt.title(\"Sample Trajectory from Model Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cba09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_most_likely_dynamics(model,\n",
    "    xlim=(-4, 4), ylim=(-3, 3), nxpts=20, nypts=20,\n",
    "    alpha=0.8, ax=None, figsize=(3, 3), K=4):\n",
    "    \n",
    "    #assert model.D == 2\n",
    "    x = np.linspace(*xlim, nxpts)\n",
    "    y = np.linspace(*ylim, nypts)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = np.column_stack((X.ravel(), Y.ravel()))\n",
    "\n",
    "    # Get the probability of each state at each xy location\n",
    "    print('Rs true grapch', model.transitions.Rs.shape)\n",
    "    print('rs true g', model.transitions.r.shape)\n",
    "    z = np.argmax(xy.dot(model.transitions.Rs.T) + model.transitions.r, axis=1)\n",
    "    print('z shape?', z.shape, z)\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    for k, (A, b) in enumerate(zip(model.dynamics.As, model.dynamics.bs)):\n",
    "        dxydt_m = xy.dot(A.T) + b - xy\n",
    "\n",
    "        zk = z == k\n",
    "        if zk.sum(0) > 0:\n",
    "            ax.quiver(xy[zk, 0], xy[zk, 1],\n",
    "                      dxydt_m[zk, 0], dxydt_m[zk, 1],\n",
    "                      color=colors[k % len(colors)], alpha=alpha)\n",
    "\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_inf(model,\n",
    "    xlim=(-4, 4), ylim=(-3, 3), nxpts=20, nypts=20,\n",
    "    alpha=0.8, ax=None, figsize=(3, 3), K=4):\n",
    "    \n",
    "    x = np.linspace(*xlim, nxpts)\n",
    "    y = np.linspace(*ylim, nypts)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = np.column_stack((X.ravel(), Y.ravel()))\n",
    "\n",
    "    # Get the probability of each state at each xy location\n",
    "    print('Rs true grapch', model.transitions.Rs.shape)\n",
    "    print('rs true g', model.transitions.r.shape)\n",
    "    \n",
    "    z = [0]\n",
    "    \n",
    "    for i, xy_iter in enumerate(xy[1:]):\n",
    "    \n",
    "        z.append(np.argmax(xy_iter.dot(model.transitions.Rs[z[i-1]].T) + model.transitions.r[z[i-1]]))\n",
    "    print('z shape?', np.array(z).shape, z)\n",
    "    z = np.array(z)\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    for k, (A, b) in enumerate(zip(model.dynamics.As, model.dynamics.bs)):\n",
    "        dxydt_m = xy.dot(A.T) + b - xy\n",
    "\n",
    "        zk = z == k\n",
    "        if zk.sum(0) > 0:\n",
    "            ax.quiver(xy[zk, 0], xy[zk, 1],\n",
    "                      dxydt_m[zk, 0], dxydt_m[zk, 1],\n",
    "                      color=colors[k % len(colors)], alpha=alpha)\n",
    "\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d742c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build true rslds\n",
    "T = 10000\n",
    "K = 4\n",
    "D_obs = 10\n",
    "D_latent = 2\n",
    "\n",
    "def make_true_model():\n",
    "    As = [random_rotation(D_latent, np.pi/24.),\n",
    "      random_rotation(D_latent, np.pi/48.)]\n",
    "\n",
    "    # Set the center points for each system\n",
    "    centers = [np.array([+2.0, 0.]),\n",
    "           np.array([-2.0, 0.])]\n",
    "    bs = [-(A - np.eye(D_latent)).dot(center) for A, center in zip(As, centers)]\n",
    "\n",
    "    # Add a \"right\" state\n",
    "    As.append(np.eye(D_latent))\n",
    "    bs.append(np.array([+0.1, 0.]))\n",
    "\n",
    "    # Add a \"right\" state\n",
    "    As.append(np.eye(D_latent))\n",
    "    bs.append(np.array([-0.25, 0.]))\n",
    "\n",
    "    # Construct multinomial regression to divvy up the space\n",
    "    w1, b1 = np.array([+1.0, 0.0]), np.array([-2.0])   # x + b > 0 -> x > -b\n",
    "    w2, b2 = np.array([-1.0, 0.0]), np.array([-2.0])   # -x + b > 0 -> x < b\n",
    "    w3, b3 = np.array([0.0, +1.0]), np.array([0.0])    # y > 0\n",
    "    w4, b4 = np.array([0.0, -1.0]), np.array([0.0])    # y < 0\n",
    "    Rs = np.row_stack((100*w1, 100*w2, 10*w3,10*w4))\n",
    "    r = np.concatenate((100*b1, 100*b2, 10*b3, 10*b4))\n",
    "    \n",
    "    true_rslds = ssm.SLDS(D_obs, K, D_latent, \n",
    "                      transitions=\"recurrent_only\",\n",
    "                      dynamics=\"diagonal_gaussian\",\n",
    "                      emissions=\"gaussian_orthog\",\n",
    "                      single_subspace=True)\n",
    "    true_rslds.dynamics.mu_init = np.tile(np.array([[0, 1]]), (K, 1))\n",
    "    true_rslds.dynamics.sigmasq_init = 1e-4 * np.ones((K, D_latent))\n",
    "    true_rslds.dynamics.As = np.array(As)\n",
    "    true_rslds.dynamics.bs = np.array(bs)\n",
    "    print('As true', true_rslds.dynamics.As.shape)\n",
    "    print('bs true', true_rslds.dynamics.bs.shape)\n",
    "    true_rslds.dynamics.sigmasq = 1e-4 * np.ones((K, D_latent))\n",
    "    \n",
    "    \n",
    "     \n",
    "    true_rslds.transitions.Rs = Rs\n",
    "    true_rslds.transitions.r = r\n",
    "    print('Rs true', true_rslds.transitions.Rs.shape)\n",
    "    print('rs true', true_rslds.transitions.r.shape)\n",
    "    \n",
    "    true_rslds.emissions.inv_etas = np.log(1e-2) * np.ones((1, D_obs))\n",
    "    return true_rslds\n",
    "\n",
    "\n",
    "true_rslds = make_true_model()\n",
    "\n",
    "\n",
    "# build infered rslds\n",
    "from numpy.linalg import inv\n",
    "def make_inf_model():\n",
    "    As = np.array([[ 0.9268,  0.0551],\n",
    "        [-0.2080,  0.9323],\n",
    "        [ 0.9952,  0.0399],\n",
    "        [-0.1017,  0.9670],\n",
    "        [ 0.9807,  0.0068],\n",
    "        [ 0.0152,  0.9635],\n",
    "        [ 0.9846,  0.0100],\n",
    "        [ 0.0219,  0.9676]])\n",
    "    As = np.reshape(As, (4,2,2))\n",
    "    \n",
    "#     for i, A in enumerate(As):\n",
    "#         As[i] = np.matmul(np.matmul(R, A), inv(R)) \n",
    "        \n",
    "\n",
    "    # Set the center points for each system\n",
    "    \n",
    "    bs = np.array([-0.1113, -0.0556, -0.0226,  0.1760, -0.0124, -0.0799,  0.0792,  0.1404])\n",
    "    bs = np.reshape(bs, (4,2))\n",
    "\n",
    "    \n",
    "    # Construct multinomial regression to divvy up the space\n",
    "    Rs = np.array([[-1.2110, -1.1055],\n",
    "        [ 1.3356, -0.2874],\n",
    "        [ 2.8323,  0.1543],\n",
    "        [ 1.1719,  0.8615],\n",
    "        [-0.5288, -0.3797],\n",
    "        [ 1.4611,  0.7638],\n",
    "        [ 0.1845, -1.2972],\n",
    "        [-0.5560, -0.6553],\n",
    "        [-0.9565, -0.7659],\n",
    "        [-0.7451,  1.1582],\n",
    "        [ 1.4352, -0.9208],\n",
    "        [-1.0619,  0.8751],\n",
    "        [ 0.0094, -0.9992],\n",
    "        [ 1.5631,  0.0360],\n",
    "        [ 0.3146, -1.5100],\n",
    "        [-0.3560,  0.7558]])\n",
    "    \n",
    "    Rs = np.reshape(Rs, (4,4,2))\n",
    "    \n",
    "    r = np.array([ 1.7372, -0.9438, -1.5308, -0.4251, -0.4980,  0.3336, -0.1542, -0.7011,\n",
    "        -0.9896, -1.5549,  0.4939, -1.6408, -1.2595, -0.6701, -0.3222,  0.6581])\n",
    "    r = np.reshape(r, (4,4))\n",
    "    \n",
    "    true_rslds = ssm.SLDS(D_obs, K, D_latent, \n",
    "                      transitions=\"recurrent_only\",\n",
    "                      dynamics=\"diagonal_gaussian\",\n",
    "                      emissions=\"gaussian_orthog\",\n",
    "                      single_subspace=True)\n",
    "    true_rslds.dynamics.mu_init = np.tile(np.array([[0, 1]]), (K, 1))\n",
    "    true_rslds.dynamics.sigmasq_init = 1e-4 * np.ones((K, D_latent))\n",
    "    true_rslds.dynamics.As = np.array(As)\n",
    "    true_rslds.dynamics.bs = np.array(bs)\n",
    "    true_rslds.dynamics.sigmasq = 1e-4 * np.ones((K, D_latent))\n",
    "    \n",
    "#     for i, rr in enumerate(Rs):\n",
    "#         Rs[i] = np.matmul(R, rr)\n",
    "#         #Rs[i] = np.matmul(np.matmul(R, A), inv(R)) \n",
    "        \n",
    "    true_rslds.transitions.Rs = Rs\n",
    "    true_rslds.transitions.r = r\n",
    "    print('Rs inf', true_rslds.transitions.Rs.shape)\n",
    "    print('rs inf', true_rslds.transitions.r.shape)\n",
    "    \n",
    "    true_rslds.emissions.inv_etas = np.log(1e-2) * np.ones((1, D_obs))\n",
    "    return true_rslds\n",
    "\n",
    "inf_rslds = make_inf_model()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.subplot(111)\n",
    "lim = abs(z).max(axis=0) + 1\n",
    "plot_most_likely_dynamics(true_rslds, xlim=(-lim[0], lim[0]), ylim=(-lim[1], lim[1]), ax=ax)\n",
    "plt.title(\"True Dynamics\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.subplot(111)\n",
    "lim = 4, 3\n",
    "plot_inf(inf_rslds, xlim=(-lim[0], lim[0]), ylim=(-lim[1], lim[1]), ax=ax)\n",
    "plt.title(\"Inferred Dynamics, rSLDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x, y\n",
    "#y, z, x = model_0.sampler(10000)\n",
    "def plot_observations(z, y, ax=None, ls=\"-\", lw=1):\n",
    "\n",
    "    zcps = np.concatenate(([0], np.where(np.diff(z))[0] + 1, [z.size]))\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        ax = fig.gca()\n",
    "    T, N = y.shape\n",
    "    t = np.arange(T)\n",
    "    for n in range(N):\n",
    "        for start, stop in zip(zcps[:-1], zcps[1:]):\n",
    "            ax.plot(t[start:stop + 1], y[start:stop + 1, n],\n",
    "                    lw=lw, ls=ls,\n",
    "                    color=colors[z[start] % len(colors)],\n",
    "                    alpha=1.0)\n",
    "    return ax\n",
    "fig = plt.figure(figsize=(15, 6)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[2, 3]) \n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "plot_observations(new_y[:1000], new_x[:1000,:1], ax=ax1)\n",
    "plt.title(\"Observations for first 1000 time steps\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39389b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
